{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sort texts by partisanship with Fast.ai (Gannett)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2FtGCN6bVsg"
      },
      "source": [
        "# Sorting ads by partisanship.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CaoHqFbIYdd"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Our challenge is to take a big corpus of political ads and sort them by partisanship. Democrats, Republicans, non-partisan and commercial (e.g. merch).\n",
        "\n",
        "I took these ads from Facebook's ad library, and you could apply it maybe to tweets or Google ads too. \n",
        "\n",
        "But note that our workflow isn't politics-specific. You could do the exact same thing to categorize court documents... or consumer complaints... or online comments.\n",
        "\n",
        "### First, the language model\n",
        "\n",
        "We'll get into the details below, but here's our two-step process for this project:\n",
        "\n",
        "First, we need a model trained to recognize the patterns of English. For that, we'd need some huge dataset of English-language text. Fortunately, someone has already done that for us! We'll be using a model trained on thousands of long Wikipedia articles. It's called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset).\n",
        "\n",
        "We'll then use _transfer learning_ (like we did for the bike video frames) to further train wikitext-103 on our particular corpus: several thousand political ads. So we benefit from it's training on both English-language articles _and_  political ads.\n",
        "\n",
        "That will give us a **language model** that's good at detecting patterns in political ads.\n",
        "\n",
        "\n",
        "### Second, the classification model\n",
        "\n",
        "Next we need a model that will sort -- aka _classify_ -- political ads into \"Republican\", \"Democrat\", and \"other\". This will combine the patern-recognition embedded in the language model and examples of both kinds of political ads to make a predition on which class _new_ political ads belong to. This is our **classification model**.\n",
        "\n",
        "\n",
        "## The Plan\n",
        "\n",
        "Here's what we're going to do:\n",
        "\n",
        "- Grab files with a bunch of political ads\n",
        "- Make a **language model** from a model pretrained on Wikipedia _plus_ all the political ads as we have\n",
        "- Make a **classification model** to predict whether an ad is political or not using a _shortcut_. Instead of hand-labeling ads, we'll hand-label advertisers.\n",
        "- Use that classification model to predict the politicalness of unseen ads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX0MZ45kIYde"
      },
      "source": [
        "## Credits\n",
        "\n",
        "This notebook was based on one originally created by Jeremy Howard and the other folks at [fast.ai](https://fast.ai) as part of [this fantastic class](https://course.fast.ai/). Specifically, it comes from Lesson 4. You can [see the lession video](https://course.fast.ai/videos/?lesson=4) and [the original class notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb). \n",
        "\n",
        "For more information about this project, and details about how to use this work in the wild, check out our [Quartz AI Studio blog post about the checkable-tweets project](https://qz.ai/?p=89).\n",
        "\n",
        "-- John Keefe, [Quartz](https://qz.com), October 2019 (updated by Jeremy Merrill, May 2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDfT21EFIYdf"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXTvy_1JIYdf"
      },
      "source": [
        "### For those using Google Colaboratory ...\n",
        "\n",
        "Be aware that Google Colab instances are ephemeral -- they vanish *Poof* when you close them, or after a period of sitting idle (currently 90 minutes), or if you use one for more than 12 hours.\n",
        "\n",
        "If you're using Google Colaboratory, be sure to set your runtime to \"GPU\" which speeds up your notebook for machine learning:\n",
        "\n",
        "![change runtime](https://qz-aistudio-public.s3.amazonaws.com/workshops/notebook_images/change_runtime_2.jpg)\n",
        "![pick gpu](https://qz-aistudio-public.s3.amazonaws.com/workshops/notebook_images/pick_gpu_2.jpg)\n",
        "\n",
        "Then run this cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "A1Pn_NxvIYdf"
      },
      "source": [
        "## This installs the most recent version of fast.ai\n",
        "!pip install --quiet fastai==2.3.1\n",
        "\n",
        "# if we're not on Google Colab, we need to do a few things to make stuff display right\n",
        "try:\n",
        "  import google.colab\n",
        "except:\n",
        "  %reload_ext autoreload\n",
        "  %autoreload 2\n",
        "  %matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q46N_RhoIYdg"
      },
      "source": [
        "Everyone needs to run the next cell, which initializes the Python libraries we'll use in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wulw8sSqIYdh"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from fastai.text.all import *\n",
        "import fastai\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vUkGMHXL0fs",
        "outputId": "cd300bc5-8730-47f0-9aba-a14a8fc2b53a"
      },
      "source": [
        "from fastai import __version__ as fastai_version\n",
        "import torch\n",
        "print(f'fastai: {fastai_version}')\n",
        "print(f\"if the fastai version ({fastai_version}) starts with a 1, go to Runtime -> Restart runtime and run the cells above again\")\n",
        "print('do we have a GPU?: {}'.format(\"yes! :)\" if torch.cuda.is_available() else \"NO, UH OH, re-read the instructions above\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai: 2.3.1\n",
            "if the fastai version (2.3.1) starts with a 1, go to Runtime -> Restart runtime and run the cells above again\n",
            "do we have a GPU?: yes! :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWWXa-NGIYdh"
      },
      "source": [
        "## The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZi_kxXAIYdi"
      },
      "source": [
        "Here's the \"training data\" we'll be using\n",
        "\n",
        "- A CSV (comma-separated values file) containing a bunch of political ads, with labels \"liberal\", \"conservative\" or \"other\" for each one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5SjDt8AYIYdi",
        "scrolled": true,
        "outputId": "f39c50d8-b8bb-4f39-9f50-7c3f2be53897"
      },
      "source": [
        "# Run this cell to download the data we'll use for this exercise\n",
        "!wget -P data/ -N https://filedn.com/lVaAxkskVxILBoUDG3XUrm7/partisanship_model_training_data_3000.csv --quiet\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1J7IbEYIYdi"
      },
      "source": [
        "We now have a CSV of labeled political ads (just their text). Let's take a look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F7bBb-iDIYdi",
        "outputId": "5d94d826-32e8-4ab7-968a-c829e249a61f"
      },
      "source": [
        "%ls data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "partisanship_model_training_data_3000.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TPvnzypbVsq"
      },
      "source": [
        "### Take a peek at the tweet data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I21aOI9xbVsr"
      },
      "source": [
        "Pulling data from Facebook's ad library (technically from a copy maintained at NYU, because Facebook's API is hard to use), I pulled 10,000 ad texts from 5-10 big advertisers with obvious partisanship, plus a few non-partisan ones (e.g. Facebook itself, some charities). Each ad is classified as having the partisanship of its advertiser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "collapsed": true,
        "id": "kWwuVUg9QHo8",
        "outputId": "3313b0cd-06c7-4e17-b466-3a402ff3cdbd"
      },
      "source": [
        "# Here I read the csv into a data frame I called `political_ads`\n",
        "# and take a look at the first few rows\n",
        "data_path = './data/'\n",
        "political_ads = pd.read_csv(data_path + 'partisanship_model_training_data_3000.csv')\n",
        "political_ads.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>archive_id</th>\n",
              "      <th>ad_creative_body</th>\n",
              "      <th>page_name</th>\n",
              "      <th>partisanship</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>193214261890684</td>\n",
              "      <td>President Trump has made enough broken promises. Now, it's time for a change.</td>\n",
              "      <td>Mike Bloomberg</td>\n",
              "      <td>liberal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190619788952147</td>\n",
              "      <td>President Trump has made enough broken promises. Now, it's time for a change.</td>\n",
              "      <td>Mike Bloomberg</td>\n",
              "      <td>liberal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>285355426019185</td>\n",
              "      <td>America is in a time of crisis. But we can’t just build back to the way things were before these crises — we have to build back better. \\n\\nIf you’re ready to elect a president who will fight for working people, protect our environment for the generations to come, and work to heal our deepest divisions, add your name right now.</td>\n",
              "      <td>Joe Biden</td>\n",
              "      <td>liberal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1043009652735139</td>\n",
              "      <td>The only constant in Trump's White House is chaos.</td>\n",
              "      <td>Mike Bloomberg</td>\n",
              "      <td>liberal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1304514473246395</td>\n",
              "      <td>Every single day since Donald Trump was elected, we’ve been looking forward to this – finally, Election Day is here.\\n\\nTake just a minute right now to confirm your polling place, and then get out and vote Trump out on Tuesday, Nov. 3!</td>\n",
              "      <td>Joe Biden</td>\n",
              "      <td>liberal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         archive_id  ... partisanship\n",
              "0   193214261890684  ...      liberal\n",
              "1   190619788952147  ...      liberal\n",
              "2   285355426019185  ...      liberal\n",
              "3  1043009652735139  ...      liberal\n",
              "4  1304514473246395  ...      liberal\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k68oC7bJIYdj"
      },
      "source": [
        "To train the language model, we want a bunch of examples of political ads. It doesn't matter that we didn't classify them as fact-checkable or not. The language model just needs _examples_ of the kinds of ads it might see. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eym6ulq0bVuz"
      },
      "source": [
        "## Building the language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62pxEwWPbVvI"
      },
      "source": [
        "First we need a model that 'understands' the rules of English, and ideally also recognizes patterns in our particular corpus, the political ads. This is the language model. \n",
        "\n",
        "We'll start with a language model pretrained on a thousands of Wikipedia articles called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset). That language model has been trained to guess the next word in a sentence based on all the previous words. It has a recurrent structure with a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
        "\n",
        "For our project, we want to infuse the Wikitext model with our particular dataset – the political ads. Because the English of political ads isn't the same as the English of Wikipedia, we'll adjust the internal parameters of the model by a little bit. That includes adding words that might be extremely common in the political ads but would be barely present in Wikipedia–and therefore might not be part of the vocabulary the model was trained on. For instance, maybe it would learn that \"defund\" is a word that occurs very often in conjunction with \"police\" -- a fact that's true of 2020 election-related text, but less true of older Wikipedia text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT0C6-vpbVvK"
      },
      "source": [
        "### Using all of our political for the language model\n",
        "\n",
        "We want as many political ads for the language model as possible to learn the patterns of political ads online.\n",
        "\n",
        "We'll start with the text of the 30,000 \"hand-coded\" political ads.\n",
        "\n",
        "But notice that I told the \"TextDataLoaders\" below where to find the \"text\" column in our CSV... \n",
        "\n",
        "But I didn't tell it where to find the partisanship label? Why is that?\n",
        "\n",
        "It's because we're not teaching a classifier yet. We're just training the language model, which doesn't care about the \"right answer\". That means if a shortcut like the one I took isn't available, you only have time to hand-label 30 or 50 or 100 training data points, **that's okay**. If you have a ton of data, it can help you even if you haven't looked at it yet!~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fU_R9lxbVv7"
      },
      "source": [
        "Fast.ai uses a concept called a \"[data loader](https://docs.fast.ai/basic_data.html)\" to handle machine-learning data, which takes care of a lot of the more fickle machine-learning data preparation. In other machine-learning frameworks, data loading can take hours to get right!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "C2rJuWVCbVv5",
        "outputId": "970dce70-78a8-453d-95bb-9bb2268d077f"
      },
      "source": [
        "path = \"./\"\n",
        "# Loading in data with the TextLMDataBunch factory class, using all the defaults\n",
        "data_for_language_model = TextDataLoaders.from_csv(path=path, csv_fname='data/partisanship_model_training_data_3000.csv', text_col='ad_creative_body', is_lm=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY0LkJCQbVwF"
      },
      "source": [
        "We can then put all of our political_ads (now labeled `data_for_language_model`) into a learner object along with the pretrained Wikitext model -- here called `AWD_LTSM`, which is downloaded the first time you'll execute the following line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EiiXrA6zbVwH"
      },
      "source": [
        "learn = language_model_learner(data_for_language_model, AWD_LSTM, metrics=[accuracy, Perplexity()], path=path, wd=0.1).to_fp16()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfAXUyLnOB_J"
      },
      "source": [
        "One of the most important settings when we actually _train_ our model is the **learning rate**. I'm not going to dive into it here (though I encourage you to explore it), but will use a fast.ai tool to find the best learning rate to start with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "W7b-Z94dbVwL",
        "outputId": "fc7dd560-3915-4dbb-d994-d43647c8c314"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=0.07585775852203369, lr_steep=0.17378008365631104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td3D3mK8TtHa"
      },
      "source": [
        "This gives us a graph of the optimal learning rate ... which is the point where the graph really dives downward (`1e-02` or so). Again, there's much more on picking and learning rates in the fast.ai course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA3dZWPachE"
      },
      "source": [
        "Now we can train the Language Model. (Essentailly, we're training it to be good at guessing the *next word* in a sentence, given all of the previous words.)\n",
        "\n",
        "The variabales we're passing are `1` to just do one cycle of learning, the learning rate of `1e-2`, and some momentum settings we won't get into here -- but these are pretty safe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "collapsed": true,
        "id": "pveLnA6kbVwQ",
        "outputId": "2f820da0-f154-4741-d4b9-a7825403a97c"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.384001</td>\n",
              "      <td>3.590874</td>\n",
              "      <td>0.338966</td>\n",
              "      <td>36.265774</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "collapsed": true,
        "id": "o-dYIVFcbVwS",
        "outputId": "f5eab2d1-dd9a-47b2-f788-170c5b705feb"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.581129</td>\n",
              "      <td>3.045116</td>\n",
              "      <td>0.395706</td>\n",
              "      <td>21.012466</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8kZOKSybVwX"
      },
      "source": [
        "To complete the fine-tuning, we \"unfreeze\" the original wikitext-103 language model and let our new training efforts work their way into the original neural network.\n",
        "\n",
        "Notice that we've booped the learning rate down by an order of magnitude. This a good idea... the Fast.ai course will tell you why."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "collapsed": true,
        "id": "kTfuNCuhbVwX",
        "outputId": "bbff3264-202b-4e36-95bc-96460a2a6b2e"
      },
      "source": [
        "# This takes a couple of minutes!\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.091274</td>\n",
              "      <td>2.495149</td>\n",
              "      <td>0.479651</td>\n",
              "      <td>12.123542</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.784382</td>\n",
              "      <td>2.341314</td>\n",
              "      <td>0.512119</td>\n",
              "      <td>10.394885</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv0mZuVhbVwd"
      },
      "source": [
        "While our accuracy may _seem_ low ... in this case it means the language model correctly guessed the next word in a sentence more than 1/3 of the time. That's pretty good! And we can see that even when it's wrong, it makes some pretty \"logical\" guesses. \n",
        "\n",
        "Let's give it a starting phrase and see how it does:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "_Wws03kmbVwd",
        "outputId": "2a75d0bf-3364-4704-eaac-7708578641f6"
      },
      "source": [
        "TEXT = \"We must stop\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 3\n",
        "\n",
        "print(\"\\n\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "We must stop by cutting off our parks , and for our NEXT HOUR , to send a strong message and a strong message to our movement . \n",
            "\n",
            " Please contribute $ 7.4 billion for the Democratic National\n",
            "\n",
            "We must stop interference in our elections by completing this election . At the next election , our country will have equal opportunity and justice and justice . But as our Supreme Court is approaching our challenge , we\n",
            "\n",
            "We must stop the spread of foreign interference by the United States . But this is why President Trump is calling on YOU to request a Democratic Convention vote to elect Democrats . \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj3aD0UebVwr"
      },
      "source": [
        "Remember, these are not real ... they were _generated_ by the model when it tried to guess each of the next words in the sentence! Generating text like this is not why we made the language model (though you can see where text-generation AI starts from!)\n",
        "\n",
        "Also note that the model is often crafting the response _in the form of a tweet!_\n",
        "\n",
        "We now save the model's encoder, which is the mathematical representation of what the language model \"understands\" about English patterns infused by our political_ads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "thkQAeQ2bVwr"
      },
      "source": [
        "learn.save_encoder('fine_tuned_enc')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt6pDPEDbVww"
      },
      "source": [
        "## Building the classifier model\n",
        "\n",
        "This is the model that will use our language model **and** the hand-coded political ads to guess if new ads are probably from Democrats, Republicans or sosething else.\n",
        "\n",
        "We'll create a new data loader that _does_ keeps track of the labels there (\"liberal\", \"conservative\", or \"other\"). We also pass in the `vocab` -- which is the list of the most useful words from the language model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ntIAhZbbbVw1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9f9f4973-54d7-4172-a441-495b5b29a929"
      },
      "source": [
        "data_for_classification = TextDataLoaders.from_csv(path=path, csv_fname='data/partisanship_model_training_data_3000.csv', vocab=data_lm.vocab, text_col='ad_creative_body', label_col='partisanship')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCwf-DyEbVxA"
      },
      "source": [
        "We can then create a model to classify political_ads. You can see that in the next two lines we include the processed, hand-coded political_ads (`data_for_classification`), the original Wikitext model (`AWD_LSTM`), and the knowledge we saved after infusing the language model with political_ads (`fine_tuned_enc`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xlJKU0g3bVxA"
      },
      "source": [
        "learn = text_classifier_learner(data_for_classification, AWD_LSTM, drop_mult=0.5, metrics=[accuracy])\n",
        "learn.load_encoder('fine_tuned_enc');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az5OuN6_hJaF"
      },
      "source": [
        "With neural networks, there are lots of tweaks you can adjust — known as \"hyperparameters\" — such as learning rate and momentum. The fast.ai defaults are pretty great, and the tools it has for finding the learning rate are super useful. I'm going to skip those details here for now. There's more to learn at [qz.ai](https://qz.ai) or at the [this great fast.ai course](https://course.fast.ai/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "S5g2xmtlbVxJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "9cb7069a-b0ec-4533-d6ad-cb255a36b74d"
      },
      "source": [
        "learn.fit_one_cycle(2, 1e-2)\n",
        "\n",
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(2, slice(1e-2/(2.6**4),1e-2))\n",
        "\n",
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(2, slice(5e-3/(2.6**4),5e-3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.755817</td>\n",
              "      <td>0.383203</td>\n",
              "      <td>0.901667</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.627984</td>\n",
              "      <td>0.334283</td>\n",
              "      <td>0.903333</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.636120</td>\n",
              "      <td>0.289766</td>\n",
              "      <td>0.861667</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.514489</td>\n",
              "      <td>0.256246</td>\n",
              "      <td>0.923333</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.407692</td>\n",
              "      <td>0.242888</td>\n",
              "      <td>0.918333</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.322286</td>\n",
              "      <td>0.132501</td>\n",
              "      <td>0.963333</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-TSQ7iDTdIG"
      },
      "source": [
        "Let's give it an example ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mBAXEa2MbVxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6549e5ca-160c-4714-bf43-51e3490611b4"
      },
      "source": [
        "example = \"We must elect Joe Biden as President this November 6\"\n",
        "learn.predict(example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('conservative', tensor(0), tensor([0.8500, 0.1439, 0.0061]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u1ptJu1UmT9"
      },
      "source": [
        "Robot 🤖 says `liberal`. We agree?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUayM3YJIYdr"
      },
      "source": [
        "Let's save our work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSOgwF1ybVyh"
      },
      "source": [
        "## Saving to Google Drive\n",
        "\n",
        "At present, your Google Colaboratory Notebook disappears when you close it — along with all of your data. If you'd like to save your model to your Google Drive, run the following cell and grant the permissions it requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Z7hCEKkuIYdr"
      },
      "source": [
        "## THIS CELL WILL ALLOW GOOGLE COLAB USERS SAVE MODELS TO YOUR GOOGLE DRIVE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR7Vt5X_LTHo"
      },
      "source": [
        "# # if you don't want to save to Google drive, remove the # on the line below, and run thatinstead\n",
        "# root_dir = './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "156olYDNIYdr"
      },
      "source": [
        "The next line will save everything we need for predictions to a file to your Google Drive in the `ai-workshops` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DfS7-BhpIYdr",
        "scrolled": true
      },
      "source": [
        "save_path = Path(root_dir + 'ai-texts/')\n",
        "save_path.mkdir(parents=True, exist_ok=True)\n",
        "learn.path = save_path\n",
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcdms4TTIYdr"
      },
      "source": [
        "Later, to load the model into your code, connect to your Google drive using the same block above that starts `from google.colab import drive ...` and then run this:\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HZyZDklsIYdr"
      },
      "source": [
        "# load the model from the 'export.pkl' file on your Google Drive\n",
        "learn = load_learner(save_path/\"export.pkl\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sC-l5Ef3Lm4O",
        "outputId": "db0b977a-d588-433f-d8ce-57cef0ddad40"
      },
      "source": [
        "example = \"Sleepy Joe will DESTROY our cities\"\n",
        "learn.predict(example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('conservative', tensor(0), tensor([0.6906, 0.2703, 0.0391]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57uA-44kVh_T"
      },
      "source": [
        "*Discussion Questions*\n",
        "\n",
        "1.   What would happen if we fed this model tweets?\n",
        "2.   To create the training dataset, I didn't hand label ads. I hand-picked a few big partisan advertisers, as a shortcut. Can you think of an example where you could maybe do something similar?\n",
        "3.   What are some possible shortcomings that a \"shortcut\" like that might cause? How would you look for those?\n",
        "4.   So far we've learned to categorize images and to categorize the text of political ads. What do we think would happen if we tried to categorize the *images* from political ads by partisanship?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVTEFqfzonn0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}